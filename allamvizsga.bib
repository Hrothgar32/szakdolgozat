@article{aytekinRealtimeRecommendationLocality2019,
  title = {Real-Time Recommendation with Locality Sensitive Hashing},
  author = {Aytekin, Ahmet Maruf and Aytekin, Tevfik},
  year = {2019},
  month = aug,
  journal = {Journal of Intelligent Information Systems},
  volume = {53},
  number = {1},
  pages = {1--26},
  issn = {0925-9902, 1573-7675},
  doi = {10.1007/s10844-019-00552-1},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/XGSVMH6L/Aytekin and Aytekin - 2019 - Real-time recommendation with locality sensitive h.pdf}
}

@inproceedings{brandFastOnlineSVD2003,
  title = {Fast Online {{SVD}} Revisions for Lightweight Recommender Systems},
  booktitle = {Proceedings of the 2003 {{SIAM International Conference}} on {{Data Mining}}},
  author = {Brand, Matthew},
  year = {2003},
  month = may,
  pages = {37--46},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611972733.4},
  abstract = {The singular value decomposition (SVD) is fundamental to many data modeling/mining algorithms, but SVD algorithms typically have quadratic complexity and require random access to complete data sets. This is problematic in most data mining settings. We detail a family of sequential update rules for adding data to a ``thin'' SVD data model, revising or removing data already incorporated into the model, and adjusting the model when the data-generating process exhibits nonstationarity. We also leverage the SVD to estimate the most probable completion of incomplete data. We use these methods to model data streams describing tables of consumer/product ratings, where fragments of rows and columns arrive in random order and individual table entries are arbitrarily added, revised, or retracted at any time. These purely online rules have very low time complexity and require a data stream cache no larger than a single user's ratings. We demonstrate this scheme in an interactive graphical movie recommender that predicts and displays ratings/rankings of thousands of movie titles in real-time as a user adjusts ratings of a small arbitrary set of probe movies. The system ``learns'' as it is used by revising the SVD in response to user ratings. Users can asynchronously join, add ratings, add movies, revise ratings, get recommendations, and delete themselves from the model.},
  isbn = {978-0-89871-545-3 978-1-61197-273-3},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/BYB8MTJN/Brand - 2003 - Fast online SVD revisions for lightweight recommen.pdf}
}

@misc{BuildingEssayRecommender,
  title = {Building an Essay Recommender System in 10 Days},
  howpublished = {https://jacobobryant.com/p/blog-essays-implementation/},
  langid = {american},
  file = {/home/hrothgar32/Zotero/storage/C7TG9RLV/blog-essays-implementation.html}
}

@article{charikarSimilarityEstimationTechniques,
  title = {Similarity {{Estimation Techniques}} from {{Rounding Algorithms}}},
  author = {Charikar, Moses S},
  pages = {9},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/5S7DJY4T/Charikar - Similarity Estimation Techniques from Rounding Alg.pdf}
}

@inproceedings{dacremaAreWeReally2019,
  title = {Are {{We Really Making Much Progress}}? {{A Worrying Analysis}} of {{Recent Neural Recommendation Approaches}}},
  shorttitle = {Are {{We Really Making Much Progress}}?},
  booktitle = {Proceedings of the 13th {{ACM Conference}} on {{Recommender Systems}}},
  author = {Dacrema, Maurizio Ferrari and Cremonesi, Paolo and Jannach, Dietmar},
  year = {2019},
  month = sep,
  eprint = {1907.06902},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {101--109},
  doi = {10.1145/3298689.3347058},
  abstract = {Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models. In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area. Source code of our experiments and full results are available at: https://github.com/MaurizioFD/RecSys2019\_DeepLearning\_Evaluation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/hrothgar32/Zotero/storage/MIPM96XP/Dacrema et al. - 2019 - Are We Really Making Much Progress A Worrying Ana.pdf;/home/hrothgar32/Zotero/storage/YU6QULUJ/1907.html}
}

@inproceedings{dasGoogleNewsPersonalization2007,
  title = {Google News Personalization: Scalable Online Collaborative Filtering},
  shorttitle = {Google News Personalization},
  booktitle = {Proceedings of the 16th International Conference on {{World Wide Web}}  - {{WWW}} '07},
  author = {Das, Abhinandan S. and Datar, Mayur and Garg, Ashutosh and Rajaram, Shyam},
  year = {2007},
  pages = {271},
  publisher = {{ACM Press}},
  address = {{Banff, Alberta, Canada}},
  doi = {10.1145/1242572.1242610},
  isbn = {978-1-59593-654-7},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/I3EHET2C/Das et al. - 2007 - Google news personalization scalable online colla.pdf}
}

@book{garnerClojureDataScience2015,
  title = {Clojure for Data Science: Statistics, Big Data, and Machine Learning for {{Clojure}} Programmers},
  shorttitle = {Clojure for Data Science},
  author = {Garner, Henry},
  year = {2015},
  isbn = {978-1-78439-750-0},
  langid = {english},
  annotation = {OCLC: 922588948},
  file = {/home/hrothgar32/Zotero/storage/EIU2YJP9/Garner - 2015 - Clojure for data science statistics, big data, an.pdf}
}

@article{goemansImprovedApproximationAlgorithms1995,
  title = {Improved Approximation Algorithms for Maximum Cut and Satisfiability Problems Using Semidefinite Programming},
  author = {Goemans, Michel X. and Williamson, David P.},
  year = {1995},
  month = nov,
  journal = {Journal of the ACM},
  volume = {42},
  number = {6},
  pages = {1115--1145},
  issn = {0004-5411},
  doi = {10.1145/227683.227684},
  keywords = {Approximation algorithms,convex optimization,randomized algorithms,satisfiability},
  file = {/home/hrothgar32/Zotero/storage/7IW46ELH/Goemans and Williamson - 1995 - Improved approximation algorithms for maximum cut .pdf}
}

@inproceedings{indykApproximateNearestNeighbors1998,
  title = {Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality},
  shorttitle = {Approximate Nearest Neighbors},
  booktitle = {Proceedings of the Thirtieth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Indyk, Piotr and Motwani, Rajeev},
  year = {1998},
  month = may,
  series = {{{STOC}} '98},
  pages = {604--613},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/276698.276876},
  isbn = {978-0-89791-962-3},
  file = {/home/hrothgar32/Zotero/storage/CY95P67Q/Indyk and Motwani - 1998 - Approximate nearest neighbors towards removing th.pdf}
}

@inproceedings{jiSuperBitLocalitySensitiveHashing2012,
  title = {Super-{{Bit Locality-Sensitive Hashing}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ji, Jianqiu and Li, Jianmin and Yan, Shuicheng and Zhang, Bo and Tian, Qi},
  year = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  file = {/home/hrothgar32/Zotero/storage/LZIL8RHD/Ji et al. - 2012 - Super-Bit Locality-Sensitive Hashing.pdf}
}

@misc{kimDebiasingNeighborAggregation2022,
  title = {Debiasing {{Neighbor Aggregation}} for {{Graph Neural Network}} in {{Recommender Systems}}},
  author = {Kim, Minseok and Oh, Jinoh and Do, Jaeyoung and Lee, Sungjin},
  year = {2022},
  month = aug,
  eprint = {2208.08847},
  eprinttype = {arxiv},
  primaryclass = {cs},
  doi = {10.1145/3511808.3557576},
  abstract = {Graph neural networks (GNNs) have achieved remarkable success in recommender systems by representing users and items based on their historical interactions. However, little attention was paid to GNN's vulnerability to exposure bias: users are exposed to a limited number of items so that a system only learns a biased view of user preference to result in suboptimal recommendation quality. Although inverse propensity weighting is known to recognize and alleviate exposure bias, it usually works on the final objective with the model outputs, whereas GNN can also be biased during neighbor aggregation. In this paper, we propose a simple but effective approach, neighbor aggregation via inverse propensity (Navip) for GNNs. Specifically, given a user-item bipartite graph, we first derive propensity score of each user-item interaction in the graph. Then, inverse of the propensity score with Laplacian normalization is applied to debias neighbor aggregation from exposure bias. We validate the effectiveness of our approach through our extensive experiments on two public and Amazon Alexa datasets where the performance enhances up to 14.2\%.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval},
  file = {/home/hrothgar32/Zotero/storage/TMMAD9TM/Kim et al. - 2022 - Debiasing Neighbor Aggregation for Graph Neural Ne.pdf;/home/hrothgar32/Zotero/storage/7SWB82PV/2208.html}
}

@misc{lemireSlopeOnePredictors2008,
  title = {Slope {{One Predictors}} for {{Online Rating-Based Collaborative Filtering}}},
  author = {Lemire, Daniel and Maclachlan, Anna},
  year = {2008},
  month = sep,
  number = {arXiv:cs/0702144},
  eprint = {cs/0702144},
  eprinttype = {arxiv},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.cs/0702144},
  abstract = {Rating-based collaborative filtering is the process of predicting how a user would rate a given item from other user ratings. We propose three related slope one schemes with predictors of the form f(x) = x + b, which precompute the average difference between the ratings of one item and another for users who rated both. Slope one algorithms are easy to implement, efficient to query, reasonably accurate, and they support both online queries and dynamic updates, which makes them good candidates for real-world systems. The basic slope one scheme is suggested as a new reference scheme for collaborative filtering. By factoring in items that a user liked separately from items that a user disliked, we achieve results competitive with slower memory-based schemes over the standard benchmark EachMovie and Movielens data sets while better fulfilling the desiderata of CF applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases},
  file = {/home/hrothgar32/Zotero/storage/3PIRZWZL/Lemire and Maclachlan - 2008 - Slope One Predictors for Online Rating-Based Colla.pdf;/home/hrothgar32/Zotero/storage/X3K7W3E5/0702144.html}
}

@article{lindenAmazonComRecommendations2003,
  title = {Amazon.Com Recommendations: Item-to-Item Collaborative Filtering},
  shorttitle = {Amazon.Com Recommendations},
  author = {Linden, G. and Smith, B. and York, J.},
  year = {2003},
  month = jan,
  journal = {IEEE Internet Computing},
  volume = {7},
  number = {1},
  pages = {76--80},
  issn = {1089-7801},
  doi = {10.1109/MIC.2003.1167344},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/6LGJWHJY/Linden et al. - 2003 - Amazon.com recommendations item-to-item collabora.pdf}
}

@misc{MonadsCuriousProgrammer,
  title = {Monads for the {{Curious Programmer}}: {{Part}} 2 | ~~{{Bartosz Milewski}}'s {{Programming Cafe}}},
  howpublished = {https://bartoszmilewski.com/2011/03/14/monads-for-the-curious-programmer-part-2/}
}

@misc{NetflixUpdateTry,
  title = {Netflix {{Update}}: {{Try This}} at {{Home}}},
  howpublished = {https://sifter.org/\textasciitilde simon/journal/20061211.html},
  file = {/home/hrothgar32/Zotero/storage/D4XLGMGS/20061211.html}
}

@misc{scaleaiTrendsRecommendationPersonalization2021,
  title = {Trends in {{Recommendation}} \& {{Personalization}} at {{Netflix}}},
  author = {{Scale AI}},
  year = {2021},
  month = dec
}

@book{sotnikovWebDevelopmentClojure2020,
  title = {Web Development with {{Clojure}}: Build Large, Maintainable Web Applications Interactively},
  shorttitle = {Web Development with {{Clojure}}},
  author = {Sotnikov, Dmitri and Brown, Scot},
  year = {2020},
  series = {The {{Pragmatic Programmers}}},
  edition = {Third edition},
  publisher = {{The Pragmatic Bookshelf}},
  address = {{Raleigh}},
  isbn = {978-1-68050-682-2},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/9ERD5ZYK/Sotnikov and Brown - 2020 - Web development with Clojure build large, maintai.pdf}
}

@article{suSurveyCollaborativeFiltering2009,
  title = {A {{Survey}} of {{Collaborative Filtering Techniques}}},
  author = {Su, Xiaoyuan and Khoshgoftaar, Taghi M.},
  year = {2009},
  month = oct,
  journal = {Advances in Artificial Intelligence},
  volume = {2009},
  pages = {1--19},
  issn = {1687-7470, 1687-7489},
  doi = {10.1155/2009/421425},
  abstract = {As one of the most successful approaches to building recommender systems, collaborative filtering (               CF               ) uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper, we first introduce CF tasks and their main challenges, such as data sparsity, scalability, synonymy, gray sheep, shilling attacks, privacy protection, etc., and their possible solutions. We then present three main categories of CF techniques: memory-based, model-based, and hybrid CF algorithms (that combine CF with other recommendation techniques), with examples for representative algorithms of each category, and analysis of their predictive performance and their ability to address the challenges. From basic techniques to the state-of-the-art, we attempt to present a comprehensive survey for CF techniques, which can be served as a roadmap for research and practice in this area.},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/62LCTFR6/Su and Khoshgoftaar - 2009 - A Survey of Collaborative Filtering Techniques.pdf}
}

@inproceedings{zhangLearningIncompleteRatings2006,
  title = {Learning from {{Incomplete Ratings Using Non-negative Matrix Factorization}}},
  booktitle = {Proceedings of the 2006 {{SIAM International Conference}} on {{Data Mining}}},
  author = {Zhang, Sheng and Wang, Weihong and Ford, James and Makedon, Fillia},
  year = {2006},
  month = apr,
  pages = {549--553},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611972764.58},
  abstract = {We use a low-dimensional linear model to describe the user rating matrix in a recommendation system. A non-negativity constraint is enforced in the linear model to ensure that each user's rating profile can be represented as an additive linear combination of canonical coordinates. In order to learn such a constrained linear model from an incomplete rating matrix, we introduce two variations on Non-negative Matrix Factorization (NMF): one based on the Expectation-Maximization (EM) procedure and the other a Weighted Nonnegative Matrix Factorization (WNMF). Based on our experiments, the EM procedure converges well empirically and is less susceptible to the initial starting conditions than WNMF, but the latter is much more computationally efficient. Taking into account the advantages of both algorithms, a hybrid approach is presented and shown to be effective in real data sets. Overall, the NMF-based algorithms obtain the best prediction performance compared with other popular collaborative filtering algorithms in our experiments; the resulting linear models also contain useful patterns and features corresponding to user communities.},
  isbn = {978-0-89871-611-5 978-1-61197-276-4},
  langid = {english},
  file = {/home/hrothgar32/Zotero/storage/MQJXFF7D/Zhang et al. - 2006 - Learning from Incomplete Ratings Using Non-negativ.pdf}
}
