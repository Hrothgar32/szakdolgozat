#+title: Felhasználói értékeléseken alapuló collaborative filtering algoritmusok kiértékelése funkcionális környezetben
#+LATEX_CLASS: book-noparts
#+LATEX_CLASS_OPTIONS: [final, 12pt] {ubb_dolgozat}
#+LATEX_HEADER_EXTRA: \submityear{2022}
#+LATEX_HEADER_EXTRA: \doctypeHU{Szakdolgozat}
#+LATEX_HEADER_EXTRA: \doctypeEN{Diploma Thesis}
#+LATEX_HEADER_EXTRA: \doctypeRO{Lucrare de licenta}
#+LATEX_HEADER_EXTRA: \specHU{Informatika}
#+LATEX_HEADER_EXTRA: \specEN{Computer Science}
#+LATEX_HEADER_EXTRA: \specRO{Informatică}
#+LATEX_HEADER_EXTRA: \titleHU{Felhasználói értékeléseken alapuló collaborative filtering algoritmusok kiértékelése funkcionális környezetben}
#+LATEX_HEADER_EXTRA: \titleEN{License thesis title}
#+LATEX_HEADER_EXTRA: \titleRO{Titlu lucrare licență}
#+LATEX_HEADER_EXTRA: \authorHU{Zediu Álmos-Ágoston}
#+LATEX_HEADER_EXTRA: \authorRO{Álmos-Ágoston Zediu}
#+LATEX_HEADER_EXTRA: \authorEN{Álmos-Ágoston Zediu}
#+LATEX_HEADER_EXTRA: \tutorHU{dr. Bodó Zalán}
#+LATEX_HEADER_EXTRA: \tutorRO{dr. Bodó Zalán}
#+LATEX_HEADER_EXTRA: \tutorEN{dr. Bodó Zalán}
#+LATEX_HEADER_EXTRA: \pagenumbering{gobble}
#+cite_export: natbib ./abbrvnat_hu.bst

* Bevezetés
Napjainkban egyre nagyobb hangsúly kerül a különböző ajánló rendszerekre, algoritmusokra melyek felhasználási területe
igencsak kiterjedt, legyen akár szó e-commerce felületek termékajánlásáról, streaming szolgáltatások ízlésmeghatározásáról,
vagy pedig a közösségi média oldalak fő bevételforrásának számító személyes reklámajánlásáról.

A dolgozat fő tematikája három széles körben alkalmazott algoritmus, algoritmuscsalád ismertetése, előnyeinek és hátrányainak
bemutatása, körbejárva az implementációs nehézségeket, kiértékelési metrikákat és az adott algoritmusok megfelelő környezetben
való felhasználását.

A három bemutatott algoritmus a Slope One, mely egy lineáris regressziónál egyszerűbb ajánlási modell egyetlen
szabad paraméterrel, a Locality Sensitive Hashing, ami a hasonló ízléssel rendelkező felhasználók értékelési vektorait egy magas ütközési
rátával rendelkező hasítófüggvénnyel csoportosítja, és a Singular Value Decomposition mátrix faktorizációs módszer, ami a felhasználók
és az értékelt elemek közötti legfontosabb látens faktorokat hozza napvilágra.

Egy másik bemutatott szempont az algoritmusok Clojure nyelvben való implementálása.  A Clojure egy funkcionális Lispre alapuló nyelv, mely a JVM
platformon fut, nagy hangsúlyt fektet az adatvezérelt programozásra, az interaktív, REPL alapú fejlesztésre és a keretrendszerek helyett
az egyszerű könyvtárakra, melyeket az Unix filozófia alapján modulárisan használunk fel.

* TODO Az adathalmazról
Az adathalmaz a Minnesotai Egyetem MovieLens adathalmaza, mely 100 000 értékelést tartalmaz 943 felhasználótól
1682 filmről. [cite:@harperMovieLensDatasetsHistory2016]
* Clojure
A Clojure egy dinamikus funkcionális nyelv, mely ötvözi a JVM platform előnyeit a Lisp nyelvek
kifejezőkészségével.
** Funkcionális nyelvekről kicsit általánosan.
A funkcionális nyelvek fő alapelve az, hogy nincs mutálható memória, és ahelyett, hogy imperatív, egymáson
és programállapoton alapuló utasításokkal dolgozunk, előtérbe helyezzük a kifejezéseket, és a "tiszta" mellékhatásoktól
mentes függvényeket, melyeknek eredménye a bemeneti paraméterektől függ.

** Funkcionális programozás Clojureben
A Clojure fő filozófiája az egyszerű adatszerkezetekkel, főleg mapekkel való modellezése a problémáknak. Ahelyett, hogy
bonyolult absztrakciókat képezünk és enkapszuláljuk az adatainkat a rajtuk végzett műveletekkel (ezáltal "objektumokat",
és "metódusokat képezve"), vagy pedig előbb bonyolult típusosztályokkal algebrai adatstruktúrákat képzünk, előtérbe
helyezzük az egyszerű adatstruktúrákat, és az egyszerű adatstruktúrákon operáló függvényeket.

A Clojureben a függvények az elsőrendű absztrakciók, képesek vagyunk akár argumentumként is kezelni őket, stb.

#+begin_src clojure :exports both :results value list
(defn my-adder [a b] (+ a b))

(def my-five-adder (partial my-adder 5))

(map my-five-adder [1, 2, 3, 4])

#+end_src

** Perzisztens adatstruktúrák
Egy lényegi kérdés ami felmerülhet funkcionális nyelvek esetén, az a memóriahasználat, és a futási idő problémája. Mivel minden változó alapvetően konstans, ezért minden egyes olyan
művelet, ami imperatív nyelvekben az eredeti adatstruktúra változtatását vette volna igénybe (új elem beszúrás, törlés, tulajdonság megváltoztatása), a funkcionális nyelvekben
egy "módosított" változatát adja vissza az eredeti algoritmusnak. Egy naiv háttérbeli implementáció esetén tehát egy esetleges tömb beszúrásnál le kellene másolni az egész tömböt.
Itt jön be a perziztencia, és a strukturális megosztás ötlete. Ha van olyan része a memóriának, ami változatlan marad az új adatstruktúrában is, fölösleges azon a memóriarészen levő
értékeket lemásolni, és több értelme van megosztani vele.

A Clojure alap adatstruktúrái az ideális hasítófákra vannak alapozva. [cite:@jayasingheExtremeAmplitudeMassive2019] [cite:@bagwellIdealHashTrees2001]. Egy konceptuális elképzelésért
rátekinthetünk erre a képre:

[[file:images/perzisztens-vektor.jpg]]

A lényegi rész az, hogy ahhoz, hogy olyan adatstruktúrák, mint a vektorok performánsak legyenek, de perzisztensek, szükségünk van
specializált bináris fák felépítésére.

** Homoikonicitás
Ami talán leginkább megkülönbözteti a Lisp nyelvcsaládban levő nyelveket a többiektől, az a  homoikonicitás [cite:@mcilroyMacroInstructionExtensions1960] tulajdonság, vagyis maga a programkód
formálható ugyanazzal a nyelvvel futás közben, mint amiben meg volt írva.

Hasonló viselkedést elérhetünk nem homoikonikus nyelvekben is, mint mondjuk a Java vagy a C# reflection rendszere, vagy
pedig a Python dekorátor szintaxisa, viszont a Lisp nyelvek makrórendszereivel azért könnyebb valamilyen szinten dolgozni, mivel nincsenek speciálisan megkülönböztetve a programban
felhasznált adatstruktúrák szintaxisai, és a programot felépítő, elágazásokat, ismétlő ciklusokat, függvénydefiníciókat jelző nyelvi struktúrák szintaxisai.

Vegyük példának okáért a következő egyszerű programot:

#+begin_src clojure :defines add-list-numbers :exports both :results value list
(defn add-list-numbers [number-list]
  (apply + number-list))

(add-list-numbers '(1 2 3 4 5))
#+end_src

#+RESULTS:
- ("#'user/add-list-numbers")
- ("15")

Látható, hogy a függvénydefiníció kerek zárójelekbe írtuk, a függvény argumentumai pedig egy vektorszerű struktúrában kaptak helyet, utána pedig maga a függvényhívás is zárójelek között volt. Érdekes módon az átadott lista szintúgy zárójelezve adódott át, viszont raktunk elé egy aposztrófot is.

Erre azért volt szükség, mivel a Lisp nyelvekben a kerek zárójel listát jelöl, és minden lista, hacsak nem jelezzük aposztróffal, függvénymeghívással jár. Annak köszönhetően viszont, hogy "listákban" programozunk, képesek vagyunk a programrészleteinket mint lista, vektor, vagy halmazelemeket
módosítani átrendezni.

*** Makrók
A Lisp makrók olyan programszerkezetek, amelyek kódrészletet kapnak argumentumként, módosítják azt, és a módosított programrészlet eredményét futtatják végül le. Fontos megjegyezni, hogy a végső kód legenerálása fordítási időben történik, nem futási időben.

Egy jó példa arra, hogyan segíthet ez fejlesztésben és talán még fontosabb, adatelemzés során, az az úgynevezett "threading" makró.

#+begin_src clojure
(defn generate-masked-grouped-ratings [dataset-path]
  (-> (load-ratings dataset-path)
      (tc/dataset)
      (tc/complete :user :item)
      (tc/group-by :user {:result-type :as-seq})))
#+end_src

Szerepe tulajdonképpen abból áll, hogy az első logikai egységet ami a nyíl mellett áll, "befűzi" a következő függvényhívás
első argumentumaként és azon függvényhívás eredményét pedig ugyanúgy befűzi a következő függvényhívás első argumentumaként, és így tovább.

Bár talán komplikáltnak tűnhet egy hasonló funkcionalitás implementálása, ezen makró forráskódja mindössze 10 sor, és
kihasználja azt, hogy a "formok" (a Clojure kód kerek zárójelbe helyezett futtatható egysége) igazából listák, így a makró feladata egyszerűen a helyes futtatható lista megalkotása.

#+begin_src clojure
(defmacro ->
  [x & forms]
  (loop [x x, forms forms]
    (if forms
      (let [form (first forms)
            threaded (if (seq? form)
                       (with-meta `(~(first form) ~x ~@(next form)) (meta form))
                       (list form x))]
        (recur threaded (next forms)))
      x)))
#+end_src
* Algoritmusok
** Slope one
A Slope One egy egyszerűen implementálható, de ennek ellenére meglepően jó eredményekkel
rendelkező algoritmuscsalád melyet Anna Maclachlan és Daniel Lemire jelentettek meg.
[cite:@lemireSlopeOnePredictors2008]

Nevét onnan kapta, hogy a amíg az egyszerű lineáris regresszió esetén két paramétert becsülünk meg,
itt elég csak egy paraméter, leegyszerűsítve a \(f(x) = ax + b\) modellt egy \(f(x) = x + b\) modellre. Abban az esetben, mikor
felhasználói értékelésekről beszélünk nem egy adott termék vagy értékelendő tárgy individuális értékeléseit vizsgáljuk,
hanem az egy-egy tárgy értékelései közötti átlagos különbséget.

[[file:images/slopeexample.png]]


*** Működési elv
Az algoritmus dióhéjban összesíti a tárgyak közötti szavazatkülönbségeket,
utána pedig ahhoz, hogy megközelítsük egy felhasználó ismeretlen szavazatát, összeadjuk a
létező szavazatait a vizsgálandó tárgy és az létező szavazatok közötti átlagos különbségekkel,
és súlyozott átlagot számolunk, ahol a súly az, hogy hányan szavaztak mindkét tárgyra.

Ha a felhasználó \(u\)-ként jelöljük, a szavazatai halmazát \(S(u)\)-ként, akkor egy \(j\) tárgyra
adott:

\begin{equation}
\hat{r}_{j|u} = \frac{\sum_{i \in S(u); i \not= j}{(\Delta{i,j} + u_{i})c_{j,i}}}{\sum_{i \in S(u) i \not= j} c_{j,i}}
\end{equation}

[cite:@lemireSlopeOnePredictors2008]

Ahol \(c_{j,i} = card(S_{j,i}(R)\) vagyis a kardinalitása a \(j\) és \(i\)-re is szavazott embereknek.

*** Implementáció
Az ebben a szekcióban levő kód nagy része Henry Garner Clojureben való gépi tanulásról
szóló könyvéből lett átvéve, [cite:@garnerClojureDataScience2015] , és a *top-n* ajánlási mechanizmussal együtt is alig tesz ki 50 sort.

Először a listakonstruktor elvű *for* makróval tárgy párokat generálunk, majd egy üres *map* asszociatív struktúrából kiindulva leredukáljuk ezeket a párokat egy mapre, melyben
minden az összes tárgyak közötti különbség el van mentve.

#+begin_src clojure
(defn conj-item-difference [dict [i j]]
  (let [difference (-  (:rating j) (:rating i))]
    (update-in dict [(:item i) (:item j)] conj difference)))

(defn collect-item-differences [dict items]
  (reduce conj-item-difference dict
          (for [i items
                j items
                :when (not= i j)]
            [i j])))

(defn item-differences [user-ratings]
  (reduce collect-item-differences {} user-ratings))
#+end_src

Ezután elmentjük a különbségek átlagát, és a közös szavazók számát.

#+begin_src clojure
(defn summarize-item-differences [related-items]
  (let [f (fn [differences]
            {:mean  (s/mean differences)
             :count (count  differences)})]
    (map-vals f related-items)))

(defn slope-one-recommender [ratings]
  (->> (item-differences ratings)
       (map-vals summarize-item-differences)))
#+end_src

A felhasználási lépésben, amikor egy adott tárgyra szeretnénk értékelést megsaccolni,
hozzáadjuk a meglevő szavazatokat a különbségekhez és elvégezzük a súlyozott átlagolást.

#+begin_src clojure
(defn candidates [recommender {:keys [rating item]}]
  (->> (get recommender item)
       (map (fn [[id {:keys [mean count]}]]
              {:item id
               :rating (+ rating mean)
               :count count}))))

(defn weighted-rating [[id candidates]]
  (let [ratings-count (reduce + (map :count candidates))
        sum-rating (map #(* (:rating %) (:count %)) candidates)
        weighted-rating (/ (reduce + sum-rating) ratings-count)]
    {:item id
     :rating weighted-rating
     :count  ratings-count}))
#+end_src

A top-n ajánlás már csak annyit ad hozzá, hogy elvégzi az egész adathalmazra a
megközelítéseket, kiveszi a vizsgált felhasználó már értékelt tárgyait, és csökkenő sorrendbe helyezi az értékeléseket.

#+begin_src clojure
(defn slope-one-recommend [recommender rated top-n]
  (let [already-rated  (set (map :item rated))
        already-rated? (fn [{:keys [id]}]
                         (contains? already-rated id))
        recommendations (->> (mapcat #(candidates recommender %)
                                     rated)
                             (group-by :item)
                             (map weighted-rating)
                             (remove already-rated?)
                             (sort-by :rating >))]
    (take top-n recommendations)))
#+end_src

** Locality sensitive hashing
A Locality Sensitive Hashing egy olyan hasítófüggvényekre alapuló módszer, ami a legtöbb hasítófüggvény implementációval ellentétben nem minimizálja az ugyanolyan kimenetek, kulcsok
számát, hanem maximalizálja, mivel a hasonló tárgyak, (esetünkben szavazatvektorok) hasonló kimenettel kell rendelkezzenek.

*** Definíció
Egy LSH séma egy olyan \(F\) hasítófüggvénycsalád, melyekre igaz, hogy a valószínűsége annak,
hogy két \(x\), \(y\) objektum függvényértéke megegyezik, megegyezik a két függvény hasonlósági távolságával valamilyen metrika szerint. [cite:@charikarSimilarityEstimationTechniques]

\begin{equation}
Pr_{h \in F} [h(x) = h(y)] = sim(x, y)
\end{equation}

ahol \(sim(x,y) \in [0,1]\) természetesen.

Ezzel egyrészt csoportosítani tudjuk a potenciálisan hasonló ízléssel rendelkezőeket, és ugyanakkor kompaktan, kevés helyfelhasználással később is fel tudjuk használni ezen csoportokat, ami segít a futási időn is persze.

*** Véletlenszerű hiperterekre alapuló LSH
Az ötlet a következő: egy \(R^{d}\)-ből levő vektorcsoport esetén mintavételezzünk egy normál eloszlású \(\overrightarrow{r}\) \(d\) dimenziós vektort. Ennek a vektornak a függvényében definiálhatjuk a következő \(h_{\overrightarrow(r)}\) függvényt:

\begin{equation}
h_{\overrightarrow(r)} (\overrightarrow{u})= \begin{cases}
                                                1 & ha \overrightarrow{r} * \overrightarrow{u} \ge 0 \\
                                                0 & ha \overrightarrow{r} * \overrightarrow{u} < 0
                                                \end{cases}
\end{equation}


Ekkor \(\overrightarrow{u}\) és \(\overrightarrow{v}\) esetén igaz lesz, hogy:


\begin{equation}
Pr_{h \in F} [h(x) = h(y)] = 1 - \frac{\theta(\overrightarrow{ u }, \overrightarrow{ v })}{\pi}
\end{equation}
[cite:@charikarSimilarityEstimationTechniques]

Vagyis annak a valószínűsége, hogy két vektor egyenkénti skaláris szorzata a véletlenszerűvel és az erre alkalmazott előjel függvény kimenete ugyanaz legyen megegyezik a két vektor között
bezárt szög koszinuszával.
Ezt először Goemans és Willamson bizonyította [cite:@goemansImprovedApproximationAlgorithms1995] egy a MAX-CUT relaxációjával foglalkozó cikkükben.

Intuitívan arról van szó, hogy ha veszünk egy \(d\)  dimenziós hiperteret, ahol \(d\) az adathalmazunkban levő tárgyak száma, akkor minden felhasználót el tudunk helyezni ebben a
hipertérben, hisz a szavazataik meghatározzák a pozíciójukat, hisz d dimenziós vektorok.

Egy véletlenszerűen felvett vektor normálvektora egy a hiperteret kettéosztó hipersíknak, vagyis
a vele való skaláris szorzat előjele meghatározza, hogy egy pont a hipersík melyik felén helyezkedik el.

Elég ilyen hipersíkot felvéve ki tudunk alakítani csoportokat, akik több hipersíknak is ugyanazon
a felén vannak, ebből következve hasonlóak.


[[file:images/randomprojection.png]]
[cite:@RandomProjectionLocality]

*** TODO Implementáció
Az első lépés a random normálvektorok legenerálása:

#+begin_src clojure
(defn generate-random-vectors [d nbits]
  (nrand/rand-normal! 0 1 (nnat/dge d nbits)))
#+end_src

A függvény amely kiszámítja mely "vödörbe kerül" egy felhasználó az értékelési vektora alapján

#+begin_src clojure
(def threshold
  "The sign function which translates a value into a binary 1 or 0."
  (fn [x]
    (if (> x 0.0)
      1.0
      0.0)))

(defn calculate-lsh-hash
  "Used to calculate the LSH hash of a random vector."
  [user-vector rand-normals]
  (. Integer parseInt (->> (ncore/mv rand-normals user-vector)
                           (fmap threshold)
                           (into [])
                           (map int)
                           (apply str)) 2))

#+end_src

A függvény amely elvégzi a "vödör" generálást, és feltölti őket.

#+begin_src clojure
(defn generate-lsh-buckets
  "Generating the buckets for the stuff."
  [all-items grouped-ratings rand-normals]
  (loop [current-rating (first grouped-ratings)
         remaining-ratings (rest grouped-ratings)
         current-user (get-in current-rating [:user 0])
         buckets {}]
    (let [sparse-vector (-> (get-sparse-ratings all-items current-rating)
                            (get-sparse-vector))
          lsh-hash (calculate-lsh-hash sparse-vector rand-normals)
          new-buckets (if (contains? buckets lsh-hash)
                        (update buckets lsh-hash conj current-user)
                        (conj buckets [lsh-hash [current-user]]))]
      (if (empty? remaining-ratings)
        new-buckets
        (recur (first remaining-ratings) (rest remaining-ratings) (get-in (first remaining-ratings) [:user 0]) new-buckets)))))
#+end_src

** Singular Value Decomposition (SVD)
*** Definíció
A Singular Value Decomposition (röviden SVD) egy mátrix faktorizációs módszer, melyben egy \(m  \times  n\) mátrixot felbontunk
\(M=U \Sigma V^{*}\) módon, ahol \(U\) egy \(m \times n\) alakú unitáris mátrix, \(\Sigma\) egy \(m \times n\) alakú diagonális mátrix, \(V\) pedig egy \(n \times n\)
unitáris mátrix. \(\Sigma\) átlón elhelyezkedő értékei a négyzetgyökei \(M * M\) sajátértékeinek, és sok SVD implementációban az értékek
csökkenő sorrendben jelennek meg \(\Sigma\) főátlóján.

*** Felhasználás ajánlórendszerekben
Hasznossága abban rejlik, hogy ha kiválasztjuk az \(r\) legnagyobb singular value-t (vagy röviden s-értéket) akkor meg tudjuk közelíteni az eredeti \(M\) mátrixot, egy másik, \(\widetilde{M}\) mátrixxal, ahol
\(rank(\widetilde{M}) = r\) [cite:@eckartApproximationOneMatrix1936a]. Ez azért tud hasznos lenni ajánlórendszerekben, mivel ezáltal le tudjuk redukálni az eltárolandó felhasználó-értékelt objektum
kapcsolatok számát, és csak a redukált \(r\) rangú \(M, \Sigma, V^{*}\) mátrixokat tárolva helyet spórolunk, ugyanakkor ki tudjuk emelni az \(r\) legfontosabb "látens faktort", amik megadják az összefüggést
bizonyos felhasználók és bizonyos filmekre adott értékelések között.

*** Implementáció
Az alkalmazott implementáció alapjául Badrul N. Sarwar, George Karypis etc, Minnesotai Egyetem kutatóinak cikke szolgál, [cite:@sarwarApplicationDimensionalityReduction2000]
és felbontható a következő stádiumokra:

Az implementációban a normalizálás az objektumok átlagos pontszámai alapján történtek, vagyis csoportosítva lettek a szavazatok objektum szerint és onnan kivontuk az átlagszavazatot:

#+begin_src clojure

(def multiple-averages (-> grouped-ratings
                    (tc/complete :user :item)
                    (tc/group-by :item {:result-type :as-seq})))

(def averages
(map
    (fn [group]
    (let [mean (-> (tc/aggregate group #(dfn/mean (% :rating)))
                    (tc/get-entry "summary" 0))
            normalized-group (-> (tc/replace-missing group :rating :value mean)
                                (tc/update-columns :rating [(partial map #(- % mean))]))]
        {:normal normalized-group
        :mean mean})) multiple-averages))
#+end_src

Az átlagos értékelések el lettek mentve, hogy az adathalmaz rekonstrukciójakor de-normalizálni tudjuk a szavazatokat, megkapva az előrejelzett értékeléseket.

Az SVD kiszámítása a LAPACK lineáris algebra könyvtár Intel MKL implentációja alapján történik.

#+begin_src clojure

(def svd (-> (nnat/dge 1680 943 (:rating new-normal))
            (nlin/svd true true)))

#+end_src

Az adathalmaz rekonstrukciója során kiválasztjuk a 14 legnagyobb s-értéket, ugyanakkor az \(U\) és \(V^{*}\) mátrixok almátrixait, gyököt vonunk a
redukált \(\Sigma\) mátrixokból, és újra összeszorozzuk őket, megkapva a 14-es ranggal rendelkező \(\widetilde{M}\) mátrixot.

#+begin_src clojure

(def sigma (-> (:sigma svd)
                (ncore/submatrix 14 14)))
(def u (ncore/submatrix (:u svd) 1680 14))
(def vt (ncore/submatrix (:vt svd) 14 943))
(def s_root (nvmath/sqrt sigma))
(def usk (ncore/mm u s_root))
(def skV (ncore/mm s_root vt))
(def usv (ncore/mm usk skV))

#+end_src

#+print_bibliography:
